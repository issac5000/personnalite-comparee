// /api/text.js
const fetch = require('node-fetch');

console.log("üîë OPENAI_API_KEY depuis Vercel:", process.env.OPENAI_API_KEY ? "OK" : "NON D√âFINIE");

// Estimation simple: ~4 caract√®res ‚âà 1 token
function estimateTokens(str) {
  if (!str) return 0;
  return Math.ceil(str.length / 4);
}

// On garde la fin de la conversation tant qu'on a du budget
function trimHistory(messages, budgetTokens) {
  const trimmed = [];
  let total = 0;

  for (let i = messages.length - 1; i >= 0; i--) {
    const m = messages[i];
    const content = typeof m.content === 'string' ? m.content : JSON.stringify(m.content);
    const cost = estimateTokens(content) + 8; // marge
    if (total + cost > budgetTokens) break;
    trimmed.push(m);
    total += cost;
  }
  return trimmed.reverse();
}

module.exports = async function gestionnaire(req, res) {
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

  if (req.method !== 'POST') {
    return res.status(405).json({ erreur: 'M√©thode non autoris√©e' });
  }

  try {
    const {
      messages = [],
      max_tokens,
      model = 'gpt-4o-mini',
      system_overrides
    } = req.body || {};

    // System prompt
    const systemMessage = {
      role: 'system',
      content: `
Tu es Psycho'Bot, l‚Äôassistant du site www.personnalitecomparee.com.

R√®gles:
- Ne perds jamais le fil: ta r√©ponse doit rester coh√©rente avec l‚Äôhistorique fourni.
- Tu ne salues et ne te pr√©sentes JAMAIS plus d‚Äôune fois; uniquement si l‚Äôutilisateur le demande.
- 100 mots max par r√©ponse (condense intelligemment).
- Tutoiement sauf si l‚Äôutilisateur vouvoie.
- Reste sur psychologie/personnalit√©/MBTI/Enn√©agramme et le site Personnalit√© Compar√©e.
- Pose toujours une question en lien avec le dernier message.
- Va droit au but.

Contexte:
- Analyse crois√©e: auto-√©valuation + 3 √©valuations externes (famille, ami, partenaire, coll√®gue).
- Mod√®les: MBTI et Enn√©agramme.
- Pond√©rations: Auto-√©val 0%, Famille 30%, Partenaire 25%, Ami 25%, Coll√®gue 15%.

Si la question sort du cadre: refuse poliment et recentre.
      `.trim()
    };

    // Injecte le system si absent
    let history = messages.slice();
    if (!history.length || history[0]?.role !== 'system') {
      history = [system_overrides ? { role: 'system', content: system_overrides } : systemMessage, ...history];
    }

    const MAX_CONTEXT_TOKENS = 2000;
    const RESPONSE_TOKENS = Math.min(500, max_tokens || 500);

    const [first, ...rest] = history;
    const trimmedRest = trimHistory(rest, MAX_CONTEXT_TOKENS);
    const finalMessages = [first, ...trimmedRest];

    const payload = {
      model,
      messages: finalMessages,
      max_tokens: RESPONSE_TOKENS,
      temperature: 0.7
    };

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${OPENAI_API_KEY}`,
      },
      body: JSON.stringify(payload),
    });

    // V√©rification si erreur API
    if (!response.ok) {
      const errorText = await response.text();
      console.error("‚ùå Erreur API OpenAI:", errorText);
      return res.status(500).json({
        error: "Erreur de l'API OpenAI",
        details: errorText
      });
    }

    let data;
    try {
      data = await response.json();
    } catch (jsonError) {
      console.error("‚ùå R√©ponse non-JSON d'OpenAI:", jsonError);
      return res.status(500).json({
        error: "R√©ponse invalide d'OpenAI",
        details: jsonError.message
      });
    }

    res.status(200).json({
      message: data.choices?.[0]?.message?.content || null,
      finish_reason: data.choices?.[0]?.finish_reason || null
    });

  } catch (error) {
    console.error("‚ùå Erreur serveur:", error);
    res.status(500).json({
      error: error.message || 'Erreur serveur'
    });
  }
};
